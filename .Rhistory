tmp_x_norm <- data_for_BVIAS(input,id_cols,var_param)
tmp_BVIAS <- BVIAS(tmp_x_norm,id_cols,var_param,F)
# least square difference between model output and average land use type values from Gallego et al., 2022
## estimate variable median for each land use type
tmp_LU_median <- tmp_x_norm %>%
group_by(land_use_type,metric_number) %>%
summarise(
x_norm = median(x_norm,na.rm = T)
) %>% ungroup()
tmp_BVIAS_median <- BVIAS(tmp_LU_median,c("land_use_type"),var_param,F)
tmp_distance <- tmp_BVIAS_median$BVIAS %>%
# calculate distance from expected values regarding Gallego et al,. 2022
mutate(
distance = case_when(
land_use_type == "arable" ~ (0.32 - BV_loc)^2,
land_use_type == "grassland" ~ (0.57 - BV_loc)^2
)
)
# Erreur quadratique moyenne
tmp_mean_sq_error = mean(tmp_distance$distance)
return(tmp_mean_sq_error)
}
sgd <- function(input,id_cols,var_param, learning_rate, epochs, epsilon) {
# test
input = tmp_BVIAS$y
id_cols = c("farm_id","crop","land_use_type")
var_param = tmp_param_var
learning_rate = 0.01
epochs = 100
tmp_gradients <- var_param
tmp_base_cost <- BVIAS_cost_function_LU(input, id_cols, var_param)
n <- nrow(input)
for (epoch in 1:epochs) {
for (i in 1:n) {
# Randomly sample a data point
index <- sample(1:n, 1)
input_i <- input[index,]
# Compute the gradient of the loss function
tmp_new_cost <-  BVIAS_cost_function_LU(input_i, id_cols, var_param)
y_pred <- BVIAS(input_i,id_cols,var_param,F)
grad_m <- -2 * input_i$x_norm * (input_i$y - y_pred)
grad_c <- -2 * (y_i - y_pred)
# Update model parameters
m <- m - learning_rate * grad_m
c <- c - learning_rate * grad_c
}
}
return(list("slope" = m, "intercept" = c))
}
# test
input = tmp_BVIAS$y
id_cols = c("farm_id","crop","land_use_type")
var_param = tmp_param_var
learning_rate = 0.01
epochs = 100
tmp_gradients <- var_param
tmp_base_cost <- BVIAS_cost_function_LU(input, id_cols, var_param)
tmp_base_cost <- BVIAS_cost_function_LU(input, id_cols,var_param =  var_param)
# test
input = tmp
id_cols = c("farm_id","crop","land_use_type")
var_param = tmp_param_var
learning_rate = 0.01
epochs = 100
tmp_gradients <- var_param
tmp_base_cost <- BVIAS_cost_function_LU(input, id_cols, var_param)
n <- nrow(input)
sgd <- function(input,id_cols,var_param, learning_rate, epochs, epsilon) {
# test
input = tmp
id_cols = c("farm_id","crop","land_use_type")
var_param = tmp_param_var
learning_rate = 0.01
epochs = 100
tmp_gradients <- var_param
tmp_base_cost <- BVIAS_cost_function_LU(input, id_cols, var_param)
n <- nrow(input)
for (epoch in 1:epochs) {
for (i in 1:n) {
# Randomly sample a data point
index <- sample(1:n, 1)
input_i <- input[index,]
# Compute the gradient of the loss function
tmp_new_cost <-  BVIAS_cost_function_LU(input_i, id_cols, var_param)
y_pred <- BVIAS(input_i,id_cols,var_param,F)
grad_m <- -2 * input_i$x_norm * (input_i$y - y_pred)
grad_c <- -2 * (y_i - y_pred)
# Update model parameters
m <- m - learning_rate * grad_m
c <- c - learning_rate * grad_c
}
}
return(list("slope" = m, "intercept" = c))
}
# Randomly sample a data point
index <- sample(1:n, 1)
input_i <- input[index,]
# Compute the gradient of the loss function
tmp_new_cost <-  BVIAS_cost_function_LU(input_i, id_cols, var_param)
tmp_gradients[i, j] <- (tmp_new_cost - tmp_base_cost) / epsilon
var_weight = tmp_param_var_weight
var_param = tmp_param_BV_constant
var_weight = tmp_param_var_weight
# then I can estimate the BVIAS
BVIAS <- function(input,id_cols,var_param,var_weight,print_plot) {
# test
#input = tmp_x_norm
#id_cols = c("farm_id","crop","land_use_type")
#var_param = tmp_param_BV_constant
#var_weight = tmp_param_var_weight
#LU_range = tmp_param_LU_range
tmp_var <- intersect(var_param$metric_number,colnames(input))
tmp_y <- input %>%
# add variable parameters
left_join(.,var_param) %>%
## calculate BV
rowwise() %>%
mutate(
## calculate BV
y = gamma + epsilon * exp(-(
abs((((x_norm)^delta) - beta) ^ alpha) /
(2*sigma^alpha)))
) %>% ungroup()
library(ggplot2)
tmp_plot <- ggplot(tmp_y) +
aes(x = x_max, y = y) +
geom_point(colour = "#112446") +
geom_smooth(se = TRUE, colour = "#112446") +
theme_minimal() +
facet_wrap(vars(metric_number),scales = "free")
tmp_BVIAS <- tmp_y %>%
# add variable weights
left_join(.,var_weight) %>%
# BV LU
# aggregate variables
group_by_at(all_of(id_cols)) %>%
summarise(
BV_LU = weighted.mean(y,weight)
) %>% ungroup() %>%
# BV NORM
# add land use type ranges
left_join(.,tibble(
# set BV_norm min and max according to Lindner et al. (2019)
land_use_type = c("grassland","arable"),
LU_min = c(0.44,0.23),
LU_max = c(0.92,0.52)
)) %>%
# normalize BV
mutate(
BV_norm = LU_min + BV_LU * (LU_max - LU_min)
) %>%
# BV LOC
mutate(
BV_loc = 1.017626088*(1-exp(-4.055847776*BV_norm)),
BVIAS_ha = 1- BV_loc
)
#return(list(tmp_plot,tmp_BVIAS))
if (print_plot == T) {
print(tmp_plot) # WIP pour A.2.1, je la trouve décroissante au lieu de croissante
}
return(list(y = tmp_y, BVIAS = tmp_BVIAS))
}
# Mean Squared Error (MSE) loss function
BVIAS_cost_function_LU <- function(input,id_cols,var_param,var_weight) {
#input = tmp
#id_cols = c("farm_id","crop","land_use_type")
#var_param = tmp_param_var
#var_weight = tmp_param_var_weight
# model output
tmp_x_norm <- data_for_BVIAS(input,id_cols,var_param)
tmp_BVIAS <- BVIAS(tmp_x_norm,id_cols,var_param,var_weight,F)
# least square difference between model output and average land use type values from Gallego et al., 2022
## estimate variable median for each land use type
tmp_LU_median <- tmp_x_norm %>%
group_by(land_use_type,metric_number) %>%
summarise(
x_norm = median(x_norm,na.rm = T)
) %>% ungroup()
tmp_BVIAS_median <- BVIAS(tmp_LU_median,c("land_use_type"),var_param,var_weight,F)
tmp_distance <- tmp_BVIAS_median$BVIAS %>%
# calculate distance from expected values regarding Gallego et al,. 2022
mutate(
distance = case_when(
land_use_type == "arable" ~ (0.32 - BV_loc)^2,
land_use_type == "grassland" ~ (0.57 - BV_loc)^2
)
)
# Erreur quadratique moyenne
tmp_mean_sq_error = mean(tmp_distance$distance)
return(tmp_mean_sq_error)
}
sgd <- function(input,id_cols,var_param,var_weight,learning_rate, epochs, epsilon) {
# test
input = tmp
id_cols = c("farm_id","crop","land_use_type")
var_param = tmp_param_var
learning_rate = 0.01
epochs = 100
tmp_gradients <- var_param
tmp_base_cost <- BVIAS_cost_function_LU(input, id_cols, var_param)
n <- nrow(input)
for (epoch in 1:epochs) {
for (i in 1:n) {
# Randomly sample a data point
index <- sample(1:n, 1)
input_i <- input[index,]
# Compute the gradient of the loss function
for (r in seq_len(nrow(var_param))) {
for (c in names(var_param)[-(1)]) { # Ignorer les colonnes non-paramètres
var_param[r, c] <- var_param[r, c] + epsilon
tmp_new_cost <-  BVIAS_cost_function_LU(input, id_cols, var_param)
tmp_gradients[r, c] <- (tmp_new_cost - tmp_base_cost) / epsilon
var_param[r, c] <- var_param[r, c] - epsilon
}
}
# Update model parameters
for (r in seq_len(nrow(var_param))) {
for (c in names(var_param)[-(1)]) { # Ignorer les colonnes non-paramètres
var_param[i, j] <- var_param[i, j] - learning_rate * gradients[i, j]
}
}
m <- m - learning_rate * grad_m
c <- c - learning_rate * grad_c
}
}
return(list("slope" = m, "intercept" = c))
}
var_weight = tmp_param_var_weight
tmp_gradients <- var_param
tmp_base_cost <- BVIAS_cost_function_LU(input, id_cols, var_param)
tmp_base_cost <- BVIAS_cost_function_LU(input, id_cols, var_param,var_weight)
n <- nrow(input)
# Randomly sample a data point
index <- sample(1:n, 1)
input_i <- input[index,]
# Compute the gradient of the loss function
for (r in seq_len(nrow(var_param))) {
for (c in names(var_param)[-(1)]) { # Ignorer les colonnes non-paramètres
var_param[r, c] <- var_param[r, c] + epsilon
tmp_new_cost <-  BVIAS_cost_function_LU(input, id_cols, var_param)
tmp_gradients[r, c] <- (tmp_new_cost - tmp_base_cost) / epsilon
var_param[r, c] <- var_param[r, c] - epsilon
}
}
epsilon = 1e-5
# Compute the gradient of the loss function
for (r in seq_len(nrow(var_param))) {
for (c in names(var_param)[-(1)]) { # Ignorer les colonnes non-paramètres
var_param[r, c] <- var_param[r, c] + epsilon
tmp_new_cost <-  BVIAS_cost_function_LU(input, id_cols, var_param)
tmp_gradients[r, c] <- (tmp_new_cost - tmp_base_cost) / epsilon
var_param[r, c] <- var_param[r, c] - epsilon
}
}
# Randomly sample a data point
index <- sample(1:n, 1)
input_i <- input[index,]
# Compute the gradient of the loss function
for (r in seq_len(nrow(var_param))) {
for (c in seq_len(ncol(var_param)-1)) { # Ignorer les colonnes non-paramètres
var_param[r, c+1] <- var_param[r, c+1] + epsilon
tmp_new_cost <-  BVIAS_cost_function_LU(input, id_cols, var_param)
tmp_gradients[r, c+1] <- (tmp_new_cost - tmp_base_cost) / epsilon
var_param[r, c+1] <- var_param[r, c+1] - epsilon
}
}
var_param[r, c+1] <- var_param[r, c+1] + epsilon
var_param[r, c+1]
View(var_param)
is.numeric(var_param)
which(is.numeric(var_param))
ncol(select_if(var_param,is.numeric))
ncol(var_param)-+ ncol(select_if(var_param,is.numeric))
ncol(var_param)- ncol(select_if(var_param,is.numeric))
seq_len(ncol(var_param))+(ncol(var_param)- ncol(select_if(var_param,is.numeric)))
# Compute the gradient of the loss function
for (r in seq_len(nrow(var_param))) {
for (c in seq_len(ncol(var_param))+(ncol(var_param)- ncol(select_if(var_param,is.numeric)))) { # Ignorer les colonnes non-paramètres
var_param[r, c] <- var_param[r, c] + epsilon
tmp_new_cost <-  BVIAS_cost_function_LU(input, id_cols, var_param)
tmp_gradients[r, c] <- (tmp_new_cost - tmp_base_cost) / epsilon
var_param[r, c] <- var_param[r, c] - epsilon
}
}
# Compute the gradient of the loss function
for (r in seq_len(nrow(var_param))) {
for (c in seq_len(ncol(var_param))+(ncol(var_param)- ncol(select_if(var_param,is.numeric)))) { # Ignorer les colonnes non-paramètres
var_param[r, c] <- var_param[r, c] + epsilon
tmp_new_cost <-  BVIAS_cost_function_LU(input, id_cols, var_param,var_weight)
tmp_gradients[r, c] <- (tmp_new_cost - tmp_base_cost) / epsilon
var_param[r, c] <- var_param[r, c] - epsilon
}
}
seq_len(ncol(select_if(var_param,is.numeric)))+(ncol(var_param)- ncol(select_if(var_param,is.numeric)))
# Compute the gradient of the loss function
for (r in seq_len(nrow(var_param))) {
for (c in seq_len(ncol(select_if(var_param,is.numeric)))+(ncol(var_param)- ncol(select_if(var_param,is.numeric)))) { # Ignorer les colonnes non-paramètres
var_param[r, c] <- var_param[r, c] + epsilon
tmp_new_cost <-  BVIAS_cost_function_LU(input, id_cols, var_param,var_weight)
tmp_gradients[r, c] <- (tmp_new_cost - tmp_base_cost) / epsilon
var_param[r, c] <- var_param[r, c] - epsilon
}
}
tmp_gradients <- var_param
tmp_base_cost <- BVIAS_cost_function_LU(input, id_cols, var_param,var_weight)
n <- nrow(input)
epochs = 10
for (epoch in 1:epochs) {
# Randomly sample a data point
index <- sample(1:n, 1)
input_i <- input[index,]
# Compute the gradient of the loss function
for (r in seq_len(nrow(var_param))) {
for (c in seq_len(ncol(select_if(var_param,is.numeric)))+(ncol(var_param)- ncol(select_if(var_param,is.numeric)))) { # Ignorer les colonnes non-paramètres
var_param[r, c] <- var_param[r, c] + epsilon
tmp_new_cost <-  BVIAS_cost_function_LU(input, id_cols, var_param,var_weight)
tmp_gradients[r, c] <- (tmp_new_cost - tmp_base_cost) / epsilon
var_param[r, c] <- var_param[r, c] - epsilon
}
}
# Update model parameters
for (r in seq_len(nrow(var_param))) {
for (c in seq_len(ncol(select_if(var_param,is.numeric)))+(ncol(var_param)- ncol(select_if(var_param,is.numeric)))) { # Ignorer les colonnes non-paramètres
var_param[r,c] <- var_param[r,c] - learning_rate * tmp_gradients[r,c]
}
}
}
View(var_param)
View(tmp_gradients)
var_param = tmp_param_var
tmp_gradients <- var_param
tmp_base_cost <- BVIAS_cost_function_LU(input, id_cols, var_param,var_weight)
n <- nrow(input)
for (epoch in 1:epochs) {
# Randomly sample a data point
index <- sample(1:n, 1)
input_i <- input[index,]
# Compute the gradient of the loss function
for (r in seq_len(nrow(var_param))) {
for (c in seq_len(ncol(select_if(var_param,is.numeric)))+(ncol(var_param)- ncol(select_if(var_param,is.numeric)))) { # Ignorer les colonnes non-paramètres
var_param[r, c] <- var_param[r, c] + epsilon
tmp_new_cost <-  BVIAS_cost_function_LU(input, id_cols, var_param,var_weight)
if (!is.na(tmp_new_cost)) {
tmp_gradients[r, c] <- (tmp_new_cost - tmp_base_cost) / epsilon
}
var_param[r, c] <- var_param[r, c] - epsilon
}
}
# Update model parameters
for (r in seq_len(nrow(var_param))) {
for (c in seq_len(ncol(select_if(var_param,is.numeric)))+(ncol(var_param)- ncol(select_if(var_param,is.numeric)))) { # Ignorer les colonnes non-paramètres
var_param[r,c] <- var_param[r,c] - learning_rate * tmp_gradients[r,c]
}
}
}
View(tmp_gradients)
View(var_param)
View(tmp_param_BV_constant)
View(tmp_param_var)
tmp_param_BV_constant_optim = var_param
# compare MSE
tmp_MSE <- BVIAS_cost_function_LU(tmp,c("farm_id","crop","land_use_type"),tmp_param_BV_constant,tmp_param_var_weight)
tmp_MSE_optim <- BVIAS_cost_function_LU(tmp,c("farm_id","crop","land_use_type"),tmp_param_BV_constant_optim,tmp_param_var_weight)
View(tmp_param_BV_constant_optim)
input = tmp
id_cols = c("farm_id","crop","land_use_type")
var_param = tmp_param_var
var_weight = tmp_param_var_weight
# model output
tmp_x_norm <- data_for_BVIAS(input,id_cols,var_param)
tmp_BVIAS <- BVIAS(tmp_x_norm,id_cols,var_param,var_weight,F)
## estimate variable median for each land use type
tmp_LU_median <- tmp_x_norm %>%
group_by(land_use_type,metric_number) %>%
summarise(
x_norm = median(x_norm,na.rm = T)
) %>% ungroup()
tmp_BVIAS_median <- BVIAS(tmp_LU_median,c("land_use_type"),var_param,var_weight,F)
tmp_distance <- tmp_BVIAS_median$BVIAS %>%
# calculate distance from expected values regarding Gallego et al,. 2022
mutate(
distance = case_when(
land_use_type == "arable" ~ (0.32 - BV_loc)^2,
land_use_type == "grassland" ~ (0.57 - BV_loc)^2
)
)
# Erreur quadratique moyenne
tmp_mean_sq_error = mean(tmp_distance$distance)
var_param = tmp_param_BV_constant_optim
# model output
tmp_x_norm <- data_for_BVIAS(input,id_cols,var_param)
tmp_BVIAS <- BVIAS(tmp_x_norm,id_cols,var_param,var_weight,F)
## estimate variable median for each land use type
tmp_LU_median <- tmp_x_norm %>%
group_by(land_use_type,metric_number) %>%
summarise(
x_norm = median(x_norm,na.rm = T)
) %>% ungroup()
View(tmp_LU_median)
tmp_BVIAS_median <- BVIAS(tmp_LU_median,c("land_use_type"),var_param,var_weight,F)
tmp_distance <- tmp_BVIAS_median$BVIAS %>%
# calculate distance from expected values regarding Gallego et al,. 2022
mutate(
distance = case_when(
land_use_type == "arable" ~ (0.32 - BV_loc)^2,
land_use_type == "grassland" ~ (0.57 - BV_loc)^2
)
)
View(tmp_distance)
View(tmp_BVIAS_median)
View(tmp_BVIAS_median[["y"]])
tmp2 = BVIAS(tmp,id_cols,tmp_param_BV_constant_optim,tmp_param_var_weight,T)
tmp2 = BVIAS(tmp,id_cols,tmp_param_BV_constant,tmp_param_var_weight,T)
# first I need to prepare the data
data_for_BVIAS <- function(input,id_cols,var_param) {
# test
#input = tmp
#id_cols = c("farm_id","crop","land_use_type")
#var_param = tmp_param_var
tmp_var <- intersect(var_param$metric_number,colnames(input))
tmp_x <- input %>%
select(all_of(id_cols),all_of(tmp_var)) %>%
pivot_longer(cols = all_of(tmp_var),names_to = "metric_number",values_to = "value")
# set 95th percentile as max
tmp_max <- tmp_x %>%
group_by(metric_number) %>%
summarise(max = as.vector(quantile(unique(value),0.95,na.rm = T))) %>% ungroup()
tmp_x_norm <- tmp_x %>%
# add max
left_join(.,tmp_max) %>%
## calculate BV
rowwise() %>%
mutate(
## set max
x_max =
case_when(
value > max ~ max,
.default =  value ),
## Normalize data
x_norm =
case_when(
value > max ~ 1,
.default =  value / max )) %>%
ungroup()
return(tmp_x_norm)
}
# then I can estimate the BVIAS
BVIAS <- function(input,id_cols,var_param,var_weight,print_plot) {
# test
#input = tmp_x_norm
#id_cols = c("farm_id","crop","land_use_type")
#var_param = tmp_param_BV_constant
#var_weight = tmp_param_var_weight
#LU_range = tmp_param_LU_range
tmp_var <- intersect(var_param$metric_number,colnames(input))
tmp_y <- input %>%
# add variable parameters
left_join(.,var_param) %>%
## calculate BV
rowwise() %>%
mutate(
## calculate BV
y = gamma + epsilon * exp(-(
abs((((x_norm)^delta) - beta) ^ alpha) /
(2*sigma^alpha)))
) %>% ungroup()
library(ggplot2)
tmp_plot <- ggplot(tmp_y) +
aes(x = x_max, y = y) +
geom_point(colour = "#112446") +
geom_smooth(se = TRUE, colour = "#112446") +
theme_minimal() +
facet_wrap(vars(metric_number),scales = "free")
tmp_BVIAS <- tmp_y %>%
# add variable weights
left_join(.,var_weight) %>%
# BV LU
# aggregate variables
group_by_at(all_of(id_cols)) %>%
summarise(
BV_LU = weighted.mean(y,weight)
) %>% ungroup() %>%
# BV NORM
# add land use type ranges
left_join(.,tibble(
# set BV_norm min and max according to Lindner et al. (2019)
land_use_type = c("grassland","arable"),
LU_min = c(0.44,0.23),
LU_max = c(0.92,0.52)
)) %>%
# normalize BV
mutate(
BV_norm = LU_min + BV_LU * (LU_max - LU_min)
) %>%
# BV LOC
mutate(
BV_loc = 1.017626088*(1-exp(-4.055847776*BV_norm)),
BVIAS_ha = 1- BV_loc
)
#return(list(tmp_plot,tmp_BVIAS))
if (print_plot == T) {
print(tmp_plot) # WIP pour A.2.1, je la trouve décroissante au lieu de croissante
}
return(list(y = tmp_y, BVIAS = tmp_BVIAS))
}
tmp2 = BVIAS(tmp,id_cols,tmp_param_BV_constant_optim,tmp_param_var_weight,T)
View(tmp_param_BV_constant_optim)
tmp <- head(tmp_input[tmp_input$land_use_type == "arable",],n = 100) %>%
rbind(.,head(tmp_input[tmp_input$land_use_type == "grassland",],n = 100))
tmp_x_norm <- data_for_BVIAS(tmp,c("farm_id","crop","land_use_type"),tmp_param_var)
tmp_BVIAS <- BVIAS(tmp_x_norm,c("farm_id","crop","land_use_type"),tmp_param_BV_constant,tmp_param_var_weight,T)
tmp_BVIAS <- BVIAS(tmp_x_norm,c("farm_id","crop","land_use_type"),tmp_param_BV_constant_optim,tmp_param_var_weight,T)
