tmp_effect_size_comp <- tibble(
"comp" = c("A.5.1/A.4.5","A.3.3/A.2.2","A.3.3/A.2.1","A.2.2/A.2.1"),
"ratio" = c(1,0.5,0.5,0.5)) %>%
mutate(
"obs" = case_when(
comp == "A.5.1/A.4.5" ~ tmp_effect_size$effect_size[tmp_effect_size$metric_number == "A.5.1"]
/ tmp_effect_size$effect_size[tmp_effect_size$metric_number == "A.4.5"],
comp == "A.3.3/A.2.2" ~ tmp_effect_size$effect_size[tmp_effect_size$metric_number == "A.3.3"]
/ tmp_effect_size$effect_size[tmp_effect_size$metric_number == "A.2.2"],
comp == "A.3.3/A.2.1" ~ tmp_effect_size$effect_size[tmp_effect_size$metric_number == "A.3.3"]
/ tmp_effect_size$effect_size[tmp_effect_size$metric_number == "A.2.1"],
comp == "A.2.2/A.2.1" ~ tmp_effect_size$effect_size[tmp_effect_size$metric_number == "A.2.2"]
/ tmp_effect_size$effect_size[tmp_effect_size$metric_number == "A.2.1"]
)
) %>%
# distance: sum of squares
mutate(
distance = (obs - ratio)^2
)
tmp_distance = sum(tmp_effect_size_comp$distance)
return(tmp_distance)
}
# Calculer la sortie actuelle du modèle
tmpl_x_norm <- practice_norm(tmp_input[1:100,],tmp_param_var,c("farm_id","crop","land_use_type"))
tmpl_current_output <- BVLU_from_practices(tmpl_x_norm,"x_norm",tmp_param_var,c("farm_id","crop","land_use_type"))
# Calculer l'erreur actuelle
tmpl_current_cost <- effect_size(tmp_input[1:100,],c("farm_id","crop","land_use_type"),tmp_param_var)
tmpl_iter = 1
# Afficher l'erreur tous les 100 itérations
if (iter %% 100 == 0) {
cat("Iteration:", iter, "Cost:", current_cost, "\n")
}
# Afficher l'erreur tous les 100 itérations
if (tmpl_iter %% 100 == 0) {
cat("Iteration:", tmpl_iter, "Cost:", tmpl_current_cost, "\n")
}
# Calculer la sortie actuelle du modèle
tmp_x_norm <- practice_norm(tmp_input[1:100,],tmp_param_var,c("farm_id","crop","land_use_type"))
tmp_BV_LU <- BVLU_from_practices(tmp_x_norm,"x_norm",tmp_param_var,c("farm_id","crop","land_use_type"))
# Calculer l'erreur actuelle
tmp_current_cost <- effect_size(tmp_input[1:100,],c("farm_id","crop","land_use_type"),tmp_param_var)
-0.33/-0.33
load("d:/users/srhuet/documents/FADN2Footprint/.RData")
rm(list = names(.GlobalEnv)[grep("tmp",names(.GlobalEnv))])
rm(id_cols,practices_to_BVIAS,tested_variable,model_parameters,input,DNM_2023_2018_14042023_135925)
save.image("~/FADN2Footprint/.RData")
library(dplyr)
if (my_DB == "RICA") {
# transfert table
tmp_TT_crops <- read_xlsx("data_in/supp_data.xlsx",sheet = "TT_crops") %>%
rename(crop = RICA_code_number)
}
if (my_DB == "FADN") {
# transfert table
tmp_FADN_crops <- read_xlsx("data_in/supp_data.xlsx",sheet = "FADN_crop_code")
tmp_TT_crops0 <- read_xlsx("data_in/supp_data.xlsx",sheet = "TT_crops")
tmp_TT_crops <- left_join(
tmp_FADN_crops %>% rename(crop = code_letter),
tmp_TT_crops0 %>% rename(crop = FADN_code_letter) %>% select(crop)
) %>% distinct()
}
library(readxl)
if (my_DB == "RICA") {
# transfert table
tmp_TT_crops <- read_xlsx("data_in/supp_data.xlsx",sheet = "TT_crops") %>%
rename(crop = RICA_code_number)
}
if (my_DB == "FADN") {
# transfert table
tmp_FADN_crops <- read_xlsx("data_in/supp_data.xlsx",sheet = "FADN_crop_code")
tmp_TT_crops0 <- read_xlsx("data_in/supp_data.xlsx",sheet = "TT_crops")
tmp_TT_crops <- left_join(
tmp_FADN_crops %>% rename(crop = code_letter),
tmp_TT_crops0 %>% rename(crop = FADN_code_letter) %>% select(crop)
) %>% distinct()
}
# WIP est-ce la bonne manière de joindre les df pour ne pas garder les fermes qu'on a retiré à chaque paramètre ???
tmp_farms <- Reduce(intersect,list(
BV_A.2.1$farm_id,
BV_A.2.2$farm_id,
BV_A.3.1$farm_id,
BV_A.3.2$farm_id,
BV_A.3.3$farm_id,
BV_A.4.3$farm_id,
BV_A.4.5$farm_id,
BV_A.5.1$farm_id))
tmp_input <- Reduce(inner_join,list(
BV_A.4.5 %>% filter(farm_id %in% tmp_farms),
BV_A.2.1 %>% filter(farm_id %in% tmp_farms),
BV_A.2.2 %>% filter(farm_id %in% tmp_farms),
BV_A.3.1 %>% filter(farm_id %in% tmp_farms),
BV_A.3.2 %>% filter(farm_id %in% tmp_farms),
BV_A.3.3 %>% filter(farm_id %in% tmp_farms),
BV_A.4.3 %>% filter(farm_id %in% tmp_farms),
BV_A.5.1 %>% filter(farm_id %in% tmp_farms)
)) %>% ungroup() %>%
# add land use type
left_join(.,tmp_TT_crops %>% select(crop,land_use_type))
# import constants of the biodiversity value contribution functions from Lindner 2019 SM
tmp_param_BV_constant <-  read_excel("data_in/supp_data.xlsx",
sheet = "Lindner_2019_BV_LU_function_con",
col_types = c("text", "text", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric"))
# plot BV contribution fonctions
tmp_test <- tibble(
x_norm = sample(seq(0,1,0.0001),length(tmp_param_BV_constant$metric_number)*100),
metric_number = rep(tmp_param_BV_constant$metric_number,100)) %>%
left_join(.,tmp_param_BV_constant) %>%
mutate(y = gamma + epsilon * exp(-(
abs((((x_norm)^delta) - beta) ^ alpha) /
(2*sigma^alpha))))
library(ggplot2)
ggplot(tmp_test) +
aes(x = x_norm, y = y) +
geom_point(colour = "#112446") +
geom_smooth(se = TRUE, colour = "#112446") +
theme_minimal() +
facet_wrap(vars(metric_number),scales = "free")
tmp_param_var_weight <- tibble(
metric_number = c(
"A.2.1","A.2.2","A.3.1","A.3.2","A.3.3",
"A.4.3","A.4.5","A.5.1")
) %>%
mutate(
weight = 1/length(metric_number)
)
tmp_param_var <- tmp_param_BV_constant %>%
left_join(.,tmp_param_var_weight) %>%
filter(!is.na(weight)) %>%
select(!Metric)
tmp_param_LU_range <- tibble(
# set BV_norm min and max according to Lindner et al. (2019)
land_use_type = c("forest","grassland","arable","mining"),
LU_min = c(1/3,1/3,1/6,0),
LU_max = c(1,5/6,2/3,1/3)
)
BVIAS <- function(input,var_param,LU_range) {
tmp_var <- intersect(var_param$metric_number,colnames(input))
tmp_x <- input %>%
select(farm_id,crop,land_use_type,all_of(tmp_var)) %>%
pivot_longer(cols = all_of(tmp_var),names_to = "metric_number",values_to = "value")
# set 95th percentile as max
tmp_max <- tmp_x %>%
group_by(metric_number) %>%
summarise(max = quantile(unique(value),0.95,na.rm = T)) %>% ungroup()
tmp_y <- tmp_x %>%
# add max
left_join(.,tmp_max) %>%
# add variable parameters
left_join(.,var_param) %>%
## calculate BV
rowwise() %>%
mutate(
## set max
x_max =
case_when(
value > max ~ max,
.default =  value ),
## Normalize data
x_norm =
case_when(
value > max ~ 1,
.default =  value / max ),
## calculate BV
y = gamma + epsilon * exp(-(
abs((((x_norm)^delta) - beta) ^ alpha) /
(2*sigma^alpha)))
) %>% ungroup()
library(ggplot2)
tmp_plot <- ggplot(tmp_y) +
aes(x = x_max, y = y) +
geom_point(colour = "#112446") +
geom_smooth(se = TRUE, colour = "#112446") +
theme_minimal() +
facet_wrap(vars(metric_number),scales = "free")
tmp_BVIAS <- tmp_y %>%
# BV LU
# aggregate variables
group_by(farm_id,crop,land_use_type) %>%
summarise(
BV_LU = weighted.mean(y,weight)
) %>% ungroup() %>%
# BV NORM
# add land use type ranges
left_join(.,LU_range) %>%
# normalize BV
mutate(
BV_norm = LU_min + BV_LU * (LU_max - LU_min)
) %>%
# BV LOC
mutate(
BV_loc = 1.017626088*(1-exp(-4.055847776*BV_norm)),
BVIAS_ha = 1- BV_loc
)
#return(list(tmp_plot,tmp_BVIAS))
print(tmp_plot) # WIP pour A.2.1, je la trouve décroissante au lieu de croissante
return(tmp_BVIAS)
}
tmp_BVIAS <- BVIAS(tmp_input[1:100,],tmp_param_var,tmp_param_LU_range)
library(tidyr)
BVIAS <- function(input,var_param,LU_range) {
tmp_var <- intersect(var_param$metric_number,colnames(input))
tmp_x <- input %>%
select(farm_id,crop,land_use_type,all_of(tmp_var)) %>%
pivot_longer(cols = all_of(tmp_var),names_to = "metric_number",values_to = "value")
# set 95th percentile as max
tmp_max <- tmp_x %>%
group_by(metric_number) %>%
summarise(max = quantile(unique(value),0.95,na.rm = T)) %>% ungroup()
tmp_y <- tmp_x %>%
# add max
left_join(.,tmp_max) %>%
# add variable parameters
left_join(.,var_param) %>%
## calculate BV
rowwise() %>%
mutate(
## set max
x_max =
case_when(
value > max ~ max,
.default =  value ),
## Normalize data
x_norm =
case_when(
value > max ~ 1,
.default =  value / max ),
## calculate BV
y = gamma + epsilon * exp(-(
abs((((x_norm)^delta) - beta) ^ alpha) /
(2*sigma^alpha)))
) %>% ungroup()
library(ggplot2)
tmp_plot <- ggplot(tmp_y) +
aes(x = x_max, y = y) +
geom_point(colour = "#112446") +
geom_smooth(se = TRUE, colour = "#112446") +
theme_minimal() +
facet_wrap(vars(metric_number),scales = "free")
tmp_BVIAS <- tmp_y %>%
# BV LU
# aggregate variables
group_by(farm_id,crop,land_use_type) %>%
summarise(
BV_LU = weighted.mean(y,weight)
) %>% ungroup() %>%
# BV NORM
# add land use type ranges
left_join(.,LU_range) %>%
# normalize BV
mutate(
BV_norm = LU_min + BV_LU * (LU_max - LU_min)
) %>%
# BV LOC
mutate(
BV_loc = 1.017626088*(1-exp(-4.055847776*BV_norm)),
BVIAS_ha = 1- BV_loc
)
#return(list(tmp_plot,tmp_BVIAS))
print(tmp_plot) # WIP pour A.2.1, je la trouve décroissante au lieu de croissante
return(tmp_BVIAS)
}
tmp_BVIAS <- BVIAS(tmp_input[1:100,],tmp_param_var,tmp_param_LU_range)
practice_norm  <- function(input,BV_constant,id_cols) {
tmp_var <- intersect(BV_constant$metric_number,colnames(input))
tmp_x <- input %>%
select(all_of(id_cols),all_of(tmp_var)) %>%
pivot_longer(cols = all_of(tmp_var),names_to = "metric_number",values_to = "value")
# set 95th percentile as max
tmp_max <- tmp_x %>%
group_by(metric_number) %>%
summarise(max = quantile(unique(value),0.95,na.rm = T)) %>%
mutate(
max = as.vector(max)
)
tmp_x_norm <- tmp_x %>%
# add max
left_join(.,tmp_max) %>%
# add constants of biodiversity value contribution function
left_join(.,BV_constant) %>%
## calculate BV
rowwise() %>%
mutate(
## set max
x_max =
case_when(
value > max ~ max,
.default =  value ),
## Normalize data
x_norm =
case_when(
value > max ~ 1,
.default =  value / max ))
return(tmp_x_norm)
}
BVLU_from_practices <- function(input,normalized_value,BV_constant,id_cols) {
tmp_y <- input %>%
rename(
normalized_value = all_of(normalized_value)
) %>%
# add constants of biodiversity value contribution function
left_join(.,BV_constant) %>%
## calculate BV
rowwise() %>%
mutate(
## calculate BV
y = gamma + epsilon * exp(-(
abs((((normalized_value)^delta) - beta) ^ alpha) /
(2*sigma^alpha)))
) %>% ungroup()
library(ggplot2)
tmp_plot <- ggplot(tmp_y) +
aes(x = normalized_value, y = y) +
geom_point(colour = "#112446") +
geom_smooth(se = TRUE, colour = "#112446") +
theme_minimal() +
facet_wrap(vars(metric_number),scales = "free")
tmp_BV_LU <- tmp_y %>%
# BV LU
# aggregate variables
group_by_at(vars(id_cols)) %>%
summarise(
BV_LU = weighted.mean(y,weight)
) %>%
ungroup() %>%
left_join(.,
tmp_y %>%
mutate(y = as.numeric(y)) %>%
select(all_of(id_cols),metric_number,y) %>%
pivot_wider(id_cols = all_of(id_cols),
names_from = metric_number,
values_from = y))
#return(list(tmp_plot,tmp_BVIAS))
print(tmp_plot)
return(tmp_BV_LU)
}
BV_loc <- function(input,LU_range,id_cols) {
tmp_BVIAS <- input %>%
# BV NORM
# add land use type ranges
left_join(.,LU_range) %>%
# normalize BV
mutate(
BV_norm = LU_min + BV_LU * (LU_max - LU_min)
) %>%
# BV LOC
mutate(
BV_loc = 1.017626088*(1-exp(-4.055847776*BV_norm)),
BVIAS_ha = 1- BV_loc
)
return(tmp_BVIAS)
}
### Cost function ----
effect_size <- function(input,id_cols,model_parameters) {
#input = tmp_input[1:100,]
#id_cols = c("farm_id","crop","land_use_type")
#model_parameters = tmp_param_var
#tested_variable = "A.3.3"
#rm(input,model_parameters,tested_variable)
tmp_x_norm <- practice_norm(input,model_parameters,id_cols)
tmp_effect_size <- tibble(
metric_number = unique(tmp_x_norm$metric_number),
effect_size = NA
)
for (tested_variable in tmp_effect_size$metric_number) {
tmp_stat_desc <- tmp_x_norm %>%
select(all_of(id_cols),metric_number,x_norm) %>%
rename(normalized_value = x_norm) %>%
group_by(metric_number) %>%
summarise(
mean = mean(normalized_value,na.rm = T),
sd = sd(normalized_value,na.rm = T),
median = median(normalized_value,na.rm = T),
q25 = as.vector(quantile(normalized_value,0.25,na.rm = T)),
q75 = as.vector(quantile(normalized_value,0.75,na.rm = T)),
q5 = as.vector(quantile(normalized_value,0.05,na.rm = T)),
q95 = as.vector(quantile(normalized_value,0.95,na.rm = T))
) %>% ungroup()
tmp_q25_input <- tmp_stat_desc %>%
mutate(
id_cols = "q25",
normalized_value = case_when(
metric_number == tested_variable ~ q25,
.default = mean
)) %>%
select(id_cols,metric_number,mean,q25,normalized_value)
tmp_q25_BVLU <- BVLU_from_practices(tmp_q25_input,"normalized_value",model_parameters,"id_cols")
tmp_q75_input <- tmp_stat_desc %>%
mutate(
id_cols = "q75",
normalized_value = case_when(
metric_number == tested_variable ~ q75,
.default = mean
)) %>%
select(id_cols,metric_number,mean,q75,normalized_value)
tmp_q75_BVLU <- BVLU_from_practices(tmp_q75_input,"normalized_value",model_parameters,"id_cols")
tmp_effect_size$effect_size[tmp_effect_size$metric_number == tested_variable] <-
tmp_q75_BVLU$BV_LU - tmp_q25_BVLU$BV_LU
}
tmp_effect_size_comp <- tibble(
"comp" = c("A.5.1/A.4.5","A.3.3/A.2.2","A.3.3/A.2.1","A.2.2/A.2.1"),
"ratio" = c(1,0.5,0.5,0.5)) %>%
mutate(
"obs" = case_when(
comp == "A.5.1/A.4.5" ~ tmp_effect_size$effect_size[tmp_effect_size$metric_number == "A.5.1"]
/ tmp_effect_size$effect_size[tmp_effect_size$metric_number == "A.4.5"],
comp == "A.3.3/A.2.2" ~ tmp_effect_size$effect_size[tmp_effect_size$metric_number == "A.3.3"]
/ tmp_effect_size$effect_size[tmp_effect_size$metric_number == "A.2.2"],
comp == "A.3.3/A.2.1" ~ tmp_effect_size$effect_size[tmp_effect_size$metric_number == "A.3.3"]
/ tmp_effect_size$effect_size[tmp_effect_size$metric_number == "A.2.1"],
comp == "A.2.2/A.2.1" ~ tmp_effect_size$effect_size[tmp_effect_size$metric_number == "A.2.2"]
/ tmp_effect_size$effect_size[tmp_effect_size$metric_number == "A.2.1"]
)
) %>%
# distance: sum of squares
mutate(
distance = (obs - ratio)^2
)
tmp_distance = sum(tmp_effect_size_comp$distance)
return(tmp_distance)
}
# Calculer la sortie actuelle du modèle
tmp_x_norm <- practice_norm(tmp_input[1:100,],tmp_param_var,c("farm_id","crop","land_use_type"))
tmp_BV_LU <- BVLU_from_practices(tmp_x_norm,"x_norm",tmp_param_var,c("farm_id","crop","land_use_type"))
# Calculer l'erreur actuelle
tmp_current_cost <- effect_size(tmp_input[1:100,],c("farm_id","crop","land_use_type"),tmp_param_var)
tmp_x_norm <- practice_norm(tmp_input[1:100,],tmp_param_var,c("farm_id","crop","land_use_type"))
tmp_param_var_weight <- tibble(
metric_number = c(
"A.2.1","A.2.2","A.3.1","A.3.2","A.3.3","A.4.3","A.4.5","A.5.1")
) %>%
mutate(
weight = case_when(
metric_number %in% c("A.4.5","A.5.1") ~ 1/3,
.default = (1/3)/(8-2)
)
)
sum(tmp_param_var_weight$weight)
1^0.5
1^0.3
2^0.3
2^0.6
View(tmp_test)
BVIAS <- function(input,var_param,LU_range,print_plot) {
tmp_var <- intersect(var_param$metric_number,colnames(input))
tmp_x <- input %>%
select(farm_id,crop,land_use_type,all_of(tmp_var)) %>%
pivot_longer(cols = all_of(tmp_var),names_to = "metric_number",values_to = "value")
# set 95th percentile as max
tmp_max <- tmp_x %>%
group_by(metric_number) %>%
summarise(max = quantile(unique(value),0.95,na.rm = T)) %>% ungroup()
tmp_y <- tmp_x %>%
# add max
left_join(.,tmp_max) %>%
# add variable parameters
left_join(.,var_param) %>%
## calculate BV
rowwise() %>%
mutate(
## set max
x_max =
case_when(
value > max ~ max,
.default =  value ),
## Normalize data
x_norm =
case_when(
value > max ~ 1,
.default =  value / max ),
## calculate BV
y = gamma + epsilon * exp(-(
abs((((x_norm)^delta) - beta) ^ alpha) /
(2*sigma^alpha)))
) %>% ungroup()
library(ggplot2)
tmp_plot <- ggplot(tmp_y) +
aes(x = x_max, y = y) +
geom_point(colour = "#112446") +
geom_smooth(se = TRUE, colour = "#112446") +
theme_minimal() +
facet_wrap(vars(metric_number),scales = "free")
tmp_BVIAS <- tmp_y %>%
# BV LU
# aggregate variables
group_by(farm_id,crop,land_use_type) %>%
summarise(
BV_LU = weighted.mean(y,weight)
) %>% ungroup() %>%
# BV NORM
# add land use type ranges
left_join(.,LU_range) %>%
# normalize BV
mutate(
BV_norm = LU_min + BV_LU * (LU_max - LU_min)
) %>%
# BV LOC
mutate(
BV_loc = 1.017626088*(1-exp(-4.055847776*BV_norm)),
BVIAS_ha = 1- BV_loc
)
#return(list(tmp_plot,tmp_BVIAS))
if (print_plot == T) {
print(tmp_plot) # WIP pour A.2.1, je la trouve décroissante au lieu de croissante
}
return(tmp_BVIAS)
}
tmp_BVIAS <- BVIAS(tmp_input[1:100,],tmp_param_var,tmp_param_LU_range)
tmp_BVIAS <- BVIAS(tmp_input[1:100,],tmp_param_var,tmp_param_LU_range,T)
1/6
sum(tmp_param_var_weight$weight) == 1
